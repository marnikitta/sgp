{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import scipy.stats\n",
    "import cvxpy as cp\n",
    "from matplotlib import pyplot as plt\n",
    "from concurrent.futures import ThreadPoolExecutor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large scale linear programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Efficient Algorithms for Global Inference in Internet Marketplaces](https://arxiv.org/pdf/2103.05277.pdf)\n",
    "- [ECLIPSE: An Extreme-Scale Linear Program Solver for Web-Applications](http://proceedings.mlr.press/v119/basu20a/basu20a.pdf)\n",
    "- [Appendix: Supplemental Material for “ECLIPSE: An Extreme-Scale Linear\n",
    "Program Solver for Web-Applications\"](http://proceedings.mlr.press/v119/basu20a/basu20a-supp.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\max_{x \\in C} \\{c^Tx + \\frac{\\gamma}{2}x^Tx\\},\\ s.t. Ax <= b$$\n",
    "\n",
    "$$g_\\gamma(\\lambda) = \\inf_{x \\in C}\\{ c^Tx + \\frac{\\gamma}{2}x^Tx + \\lambda^T(Ax - b)\\}$$\n",
    "\n",
    "$$x(\\lambda) = \\prod_{C}(A^T\\lambda + c)$$\n",
    "\n",
    "$$\\nabla g_\\gamma(\\lambda) = Ax(\\lambda) + b$$\n",
    "\n",
    "$$\\lambda^{k+1} = (\\lambda^k + \\eta \\nabla g_\\gamma(\\lambda^k)_+$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f91874c4bd0>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_users = 1000000\n",
    "n_blocks = 10\n",
    "\n",
    "click_probas = scipy.stats.norm(0, 1).rvs((n_users, n_blocks))\n",
    "click_probas[:, 3] += 2\n",
    "click_probas = scipy.special.expit(click_probas)\n",
    "\n",
    "hide_probas = scipy.stats.norm(-4, 1).rvs((n_users, n_blocks))\n",
    "hide_probas[:, 4] += 2\n",
    "hide_probas = scipy.special.expit(hide_probas)\n",
    "\n",
    "max_clicks = click_probas.sum(axis=0)\n",
    "\n",
    "plt.hist(hide_probas.ravel(), label='hides', bins=100, alpha=0.6)\n",
    "plt.hist(click_probas.ravel(), label='clicks', bins=100, alpha=0.6)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplex projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Статья с алгоритмом](https://dl.acm.org/doi/10.1145/1390156.1390191)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 7 µs, total: 18 µs\n",
      "Wall time: 21.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def simplex_projection(w):\n",
    "    w_sorted = np.flip(np.sort(w, axis=1), axis=1)\n",
    "    w_cumsum = np.cumsum(w_sorted, axis=1) - 1\n",
    "    t = w_sorted - w_cumsum / (np.arange(w.shape[1]) + 1).reshape(1, -1)\n",
    "    t[t <= 0] = np.inf\n",
    "    rho = np.argmin(t, axis=1)\n",
    "    theta = w_cumsum[np.arange(w.shape[0]), rho] / (rho + 1)\n",
    "    y = w - theta.reshape(-1, 1)\n",
    "    y[y < 0] = 0\n",
    "\n",
    "    assert y.shape == w.shape\n",
    "    assert np.allclose(y.sum(axis=1), 1)\n",
    "    assert np.all(y >= 0)\n",
    "\n",
    "    return y\n",
    "\n",
    "def fast_simplex_projection(w, workers=16):\n",
    "    block = (w.shape[0] // (workers * 5))\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=workers) as pool:\n",
    "        result2 = pool.map(simplex_projection, [w[i:i+block] for i in range(0, w.shape[0], block)])\n",
    "        result2 = np.vstack(list(result2))\n",
    "    return result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 420 ms, sys: 127 ms, total: 547 ms\n",
      "Wall time: 549 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result1 = simplex_projection(click_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 553 ms, sys: 175 ms, total: 729 ms\n",
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result2 = fast_simplex_projection(click_probas)\n",
    "\n",
    "assert np.alltrue(result2 == result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 s, sys: 377 ms, total: 2.1 s\n",
      "Wall time: 1.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_show_proba = np.ones_like(click_probas)\n",
    "test_min_clicks = max_clicks * 0.01\n",
    "test_max_hides = np.sum(np.min(hide_probas, axis=1)) * 0.8\n",
    "\n",
    "test_lambd = np.ones(click_probas.shape[1] + 1)\n",
    "\n",
    "def A_dot_x(click_probas, hide_probas, show_proba):\n",
    "    return np.hstack((-np.sum(show_proba * click_probas, axis=0), np.sum(show_proba * hide_probas)))\n",
    "assert A_dot_x(click_probas, hide_probas, test_show_proba).shape == test_lambd.shape\n",
    "\n",
    "def At_dot_lambda(clicks_probas, hide_probas, lambd):\n",
    "    return -clicks_probas * lambd[:-1] + hide_probas * lambd[-1]\n",
    "assert At_dot_lambda(click_probas, hide_probas, test_lambd).shape == click_probas.shape\n",
    "\n",
    "def At_dot_lambda_p_c(click_probas, hide_probas, lambd):\n",
    "    return At_dot_lambda(click_probas, hide_probas, lambd) - click_probas\n",
    "assert At_dot_lambda_p_c(click_probas, hide_probas, test_lambd).shape == click_probas.shape\n",
    "\n",
    "def x_lambda(click_probas, hide_probas, lambd, gamma):\n",
    "    return fast_simplex_projection(At_dot_lambda_p_c(click_probas, hide_probas, lambd) * -1. / gamma)\n",
    "assert x_lambda(click_probas, hide_probas, test_lambd, gamma=1).shape == click_probas.shape\n",
    "\n",
    "\n",
    "def grad_g(click_probas, hide_probas, lambd, min_clicks, max_hides, gamma):\n",
    "    assert click_probas.shape == hide_probas.shape\n",
    "    assert lambd.shape[0] == click_probas.shape[1] + 1\n",
    "    \n",
    "    show_proba = x_lambda(click_probas, hide_probas, lambd, gamma)\n",
    "    grad = A_dot_x(click_probas, hide_probas, show_proba) \n",
    "    \n",
    "    grad[:-1] += min_clicks\n",
    "    grad[-1] = grad[-1] - max_hides\n",
    "\n",
    "    target = -np.sum(click_probas * show_proba) + gamma / 2 * np.sum(show_proba * show_proba)\n",
    "\n",
    "    g = target + lambd.dot(grad)\n",
    "    return g, grad, target\n",
    "\n",
    "assert grad_g(click_probas, hide_probas, test_lambd, test_min_clicks, test_max_hides, 1)[1].shape == test_lambd.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.44 s, sys: 2.7 s, total: 12.1 s\n",
      "Wall time: 6.37 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7424460776972988"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gamma = 1e-2\n",
    "scipy.optimize.check_grad(lambda x: grad_g(click_probas, hide_probas, x, test_min_clicks, test_max_hides, gamma)[0],\n",
    "                          lambda x: grad_g(click_probas, hide_probas, x, test_min_clicks, test_max_hides, gamma)[1],\n",
    "                          test_lambd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtracking + оценка константы липшеца"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eclipse(click_probas, hide_probas, min_clicks, max_hides, gamma=1e-1, verbose=True):\n",
    "\n",
    "    lambd = np.ones(click_probas.shape[1] + 1)\n",
    "\n",
    "    target_history = []\n",
    "    dual_history = []\n",
    "\n",
    "    grad_old, lambd_old = None, None\n",
    "    hist = []\n",
    "\n",
    "    g, grad, _ = grad_g(click_probas, hide_probas, lambd, min_clicks, max_hides, gamma)\n",
    "\n",
    "    for i in range(200):    \n",
    "        if len(hist) > 0:\n",
    "            eta = 1 / (np.max(hist))\n",
    "        else:\n",
    "            # Первый шаг пристрелочный, дальше оцениваем константу липшеца по истории\n",
    "            eta = 1e-9\n",
    "\n",
    "        while True:\n",
    "            lambd_eta = np.maximum(lambd + eta * grad, 0)\n",
    "            g_eta, grad_eta, f_eta = grad_g(click_probas, hide_probas, lambd_eta, max_clicks * slack, max_hides, gamma)\n",
    "\n",
    "            if g_eta < g - 1e-5 * eta * grad.dot(grad): # Armijo condition\n",
    "                eta = eta / 2\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        if g > g_eta:\n",
    "            break\n",
    "\n",
    "        if len(hist) > 0 and verbose:\n",
    "            print(f'primal={f_eta:.2f}, dual={g_eta:.2f}, gap={f_eta - g_eta:.2f}, eta={eta:2f}, L_max={1 / np.max(hist):2f}')\n",
    "\n",
    "        if grad_old is not None and lambd_old is not None:\n",
    "            L = (scipy.linalg.norm(grad - grad_old) / scipy.linalg.norm(lambd - lambd_old))\n",
    "            if np.isfinite(L) and L > 0:\n",
    "                hist.append(L)\n",
    "                hist = hist[-5:]\n",
    "\n",
    "        lambd_old = lambd\n",
    "        lambd = lambd_eta\n",
    "\n",
    "        grad_old = grad\n",
    "        g, grad = g_eta, grad_eta\n",
    "\n",
    "        target_history.append(f_eta)\n",
    "        dual_history.append(g_eta)\n",
    "\n",
    "        if np.abs(f_eta - g_eta) / (1 + np.abs(f_eta) + np.abs(g_eta)) < 1e-7:\n",
    "            break\n",
    "            \n",
    "    return {'x': click_probas, 'dual': lambd, 'gaps': np.array(target_history) - np.array(dual_history)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primal=-752278.81, dual=-1261741.29, gap=509462.48, eta=0.000001, L_max=0.000001\n",
      "primal=-743558.04, dual=-1204032.27, gap=460474.23, eta=0.000001, L_max=0.000001\n",
      "primal=-735768.66, dual=-1160620.99, gap=424852.33, eta=0.000001, L_max=0.000001\n",
      "primal=-729599.37, dual=-1123484.63, gap=393885.26, eta=0.000001, L_max=0.000001\n",
      "primal=-724764.14, dual=-1089313.73, gap=364549.59, eta=0.000001, L_max=0.000001\n",
      "primal=-720952.56, dual=-1056627.52, gap=335674.96, eta=0.000001, L_max=0.000001\n",
      "primal=-717762.02, dual=-1023039.94, gap=305277.92, eta=0.000001, L_max=0.000001\n",
      "primal=-719054.24, dual=-899395.67, gap=180341.43, eta=0.000005, L_max=0.000005\n",
      "primal=-787384.48, dual=-802796.97, gap=15412.48, eta=0.000007, L_max=0.000007\n",
      "primal=-789194.44, dual=-797542.97, gap=8348.52, eta=0.000009, L_max=0.000009\n",
      "primal=-788568.63, dual=-796291.27, gap=7722.64, eta=0.000003, L_max=0.000003\n",
      "primal=-788716.13, dual=-795092.43, gap=6376.30, eta=0.000003, L_max=0.000003\n",
      "primal=-788863.09, dual=-793945.28, gap=5082.19, eta=0.000003, L_max=0.000003\n",
      "primal=-788992.66, dual=-792852.92, gap=3860.26, eta=0.000003, L_max=0.000003\n",
      "primal=-789102.69, dual=-791818.64, gap=2715.95, eta=0.000003, L_max=0.000003\n",
      "primal=-789156.94, dual=-789202.66, gap=45.72, eta=0.000019, L_max=0.000019\n"
     ]
    }
   ],
   "source": [
    "slack = np.repeat(0.0001, click_probas.shape[1])\n",
    "slack[7] = 0.5\n",
    "min_clicks = max_clicks * slack\n",
    "\n",
    "max_hides = np.sum(np.min(hide_probas, axis=1)) * 10\n",
    "\n",
    "solution = eclipse(click_probas, hide_probas, min_clicks, max_hides, gamma=1e-1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.   0.   0.   0.   0.   0.   0.48 0.   0.   0.  ]\n",
      "hides: 213967.0 <= 48663.0\n",
      "500228: 293647 >= 50\n",
      "499763: 293148 >= 49\n",
      "500161: 293570 >= 50\n",
      "844455: 728667 >= 84\n",
      "500180: 293542 >= 50\n",
      "499352: 292763 >= 49\n",
      "500168: 293508 >= 50\n",
      "500378: 293731 >= 250189\n",
      "500227: 293510 >= 50\n",
      "500103: 293418 >= 50\n"
     ]
    }
   ],
   "source": [
    "show_proba = solution['x']\n",
    "\n",
    "clicks = (click_probas * show_proba).sum(axis=0).astype(np.int)\n",
    "views = (show_proba).sum(axis=0).astype(np.int)\n",
    "\n",
    "bounds = min_clicks.astype(np.int)\n",
    "\n",
    "print(lambd.round(2))\n",
    "print(f'hides: {np.sum(hide_probas * show_proba).round()} <= {max_hides.round()}')\n",
    "for v, c, b in zip(views, clicks, bounds):\n",
    "    print(f'{v}: {c} >= {b}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/cvxpy/problems/problem.py:1279: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  \"Solution may be inaccurate. Try another solver, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value is nan\n",
      "A dual solution is\n",
      "[nan nan nan nan nan nan nan nan nan nan]\n",
      "CPU times: user 1min 1s, sys: 54.3 s, total: 1min 55s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x = cp.Variable(click_probas.shape)\n",
    "\n",
    "prob = cp.Problem(cp.Maximize(cp.sum(cp.multiply(x, click_probas))),\n",
    "                 [cp.sum(cp.multiply(x, click_probas), axis=0) >= min_clicks, \n",
    "                  cp.sum(cp.multiply(x, hide_probas)) <= max_hides,\n",
    "                  x >= 0, \n",
    "                  cp.sum(x, axis=1) == 1])\n",
    "prob.solve(verbose=False)\n",
    "\n",
    "# Print result.\n",
    "print(\"\\nThe optimal value is\", prob.value)\n",
    "print(\"A dual solution is\")\n",
    "print(prob.constraints[0].dual_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
